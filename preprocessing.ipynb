{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import ttest_1samp, ttest_rel, sem, t, zscore, chi2_contingency, fisher_exact\n",
    "import pingouin as pg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen fürs Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align x positions on the same point\n",
    "def align_x_position(x_list):\n",
    "    if not x_list:  \n",
    "        return x_list\n",
    "    shift_amount = x_list[0] - 960 \n",
    "    return [x - shift_amount for x in x_list] \n",
    "\n",
    "def flip_y_pos(y_list):\n",
    "    return [-y for y in y_list] \n",
    "\n",
    "# auf 0,0 normalisieren jeden trial\n",
    "def normalize_positions(row): \n",
    "    x_positions = row[\"xpos\"]\n",
    "    y_positions = row[\"ypos\"]\n",
    "    \n",
    "    x_start, y_start = x_positions[0], y_positions[0]\n",
    "\n",
    "    row[\"xpos\"] = [x - x_start for x in x_positions]\n",
    "    row[\"ypos\"] = [y - y_start for y in y_positions]\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Interpolation auf 100 Zeiteinheiten\n",
    "def interpolate_positions(row):\n",
    "    original_length = len(row[\"xpos\"])\n",
    "    original_time = np.linspace(0, 1, original_length)  \n",
    "    new_time = np.linspace(0, 1, 100)\n",
    "    \n",
    "    row[\"xpos\"] = np.interp(new_time, original_time, row[\"xpos\"])\n",
    "    row[\"ypos\"] = np.interp(new_time, original_time, row[\"ypos\"])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen und vorbereiten der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0, 14.86868686868687, 36.60606060606061, 55...\n",
       "1       [0.0, 6.363636363636364, 15.181818181818183, 2...\n",
       "2       [0.0, 10.282828282828284, 24.484848484848488, ...\n",
       "3       [0.0, 0.9595959595959597, 1.9191919191919193, ...\n",
       "4       [0.0, 7.757575757575758, 16.454545454545457, 2...\n",
       "                              ...                        \n",
       "1243    [0.0, 10.909090909090908, 25.81818181818182, 4...\n",
       "1244    [0.0, 5.666666666666667, 11.484848484848486, 1...\n",
       "1245    [0.0, 3.7575757575757573, 8.393939393939394, 1...\n",
       "1246    [0.0, 5.6565656565656575, 11.444444444444446, ...\n",
       "1247    [0.0, 5.93939393939394, 11.878787878787879, 17...\n",
       "Name: ypos, Length: 1248, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = \"data\"\n",
    "mouse_data_regex = r\"mouse_data_(\\d+)\"\n",
    "grouped_data = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    mouse_data_match = re.search(mouse_data_regex, filename)\n",
    "\n",
    "    if mouse_data_match:\n",
    "        participant_num = int(mouse_data_match.group(1))\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        df_mouse_data =  pd.read_csv(file_path, sep=\",\")\n",
    "        grouped_mouse_data = df_mouse_data.groupby([\"blocknumber\", \"trialnumber\"]).agg({\n",
    "            \"timedifference\": list,  \n",
    "            \"xpos\": list,            \n",
    "            \"ypos\": list             \n",
    "        }).reset_index()    \n",
    "\n",
    "        grouped_mouse_data[\"xpos\"] = grouped_mouse_data[\"xpos\"].apply(align_x_position)\n",
    "\n",
    "        grouped_mouse_data[\"ypos\"] = grouped_mouse_data[\"ypos\"].apply(flip_y_pos)\n",
    "        \n",
    "        grouped_mouse_data = grouped_mouse_data.apply(normalize_positions, axis=1)\n",
    "\n",
    "        grouped_mouse_data = grouped_mouse_data.apply(interpolate_positions, axis=1)\n",
    "\n",
    "        grouped_mouse_data[\"participant_num\"] = participant_num\n",
    "\n",
    "        grouped_data.append(grouped_mouse_data)\n",
    "\n",
    "grouped_data[0][\"ypos\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_0_participants = [1, 6, 2, 4, 9, 11, 13, 15] \n",
    "\n",
    "\n",
    "condition_0_data_mouse = []\n",
    "condition_1_data_mouse = []\n",
    "\n",
    "for grouped_mouse_data in grouped_data:\n",
    "    if grouped_mouse_data['participant_num'].iloc[0] in condition_0_participants:\n",
    "        condition_0_data_mouse.append(grouped_mouse_data)\n",
    "    else:\n",
    "        condition_1_data_mouse.append(grouped_mouse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data\"\n",
    "\n",
    "trial_data_regex = r\"trial_data_(\\d+)\"\n",
    "\n",
    "all_trial_data = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    trial_data_match = re.search(trial_data_regex, filename)\n",
    "\n",
    "    if trial_data_match:\n",
    "        participant_num = int(trial_data_match.group(1))\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        df_trial_data = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "        df_trial_data[\"currentcongruency\"] = (df_trial_data[\"currentdirection\"] == df_trial_data[\"currentlocation\"]).astype(int)\n",
    "        df_trial_data[\"previouscongruency\"] = (df_trial_data[\"previousdirection\"] == df_trial_data[\"previouslocation\"]).astype(int)\n",
    "\n",
    "        df_trial_data[\"participant_num\"] = participant_num\n",
    "\n",
    "        all_trial_data.append(df_trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_0_participants = [1, 6, 2, 4, 9, 11, 13, 15] \n",
    "\n",
    "condition_0_data_trial = []\n",
    "condition_1_data_trial = []\n",
    "\n",
    "for df in all_trial_data:\n",
    "    participant_num = df[\"participant_num\"].iloc[0]\n",
    "    \n",
    "    if participant_num in condition_0_participants:\n",
    "        condition_0_data_trial.append(df)\n",
    "    else:\n",
    "        condition_1_data_trial.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_0_with_latency = []\n",
    "condition_0_no_latency = []\n",
    "\n",
    "for trial_list in condition_0_data_trial:\n",
    "    df = pd.DataFrame(trial_list)\n",
    "    \n",
    "    with_latency = df.loc[df[\"blocknumber\"].isin([1, 2])].copy()\n",
    "    no_latency = df.loc[df[\"blocknumber\"].isin([3, 4])].copy()\n",
    "    \n",
    "    condition_0_with_latency.append(with_latency)\n",
    "    condition_0_no_latency.append(no_latency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_1_with_latency = []\n",
    "condition_1_no_latency = []\n",
    "\n",
    "for trial_list in condition_1_data_trial:\n",
    "    df = pd.DataFrame(trial_list)\n",
    "    \n",
    "    with_latency = df.loc[df[\"blocknumber\"].isin([3, 4])].copy()\n",
    "    no_latency = df.loc[df[\"blocknumber\"].isin([1, 2])].copy()\n",
    "    \n",
    "    condition_1_with_latency.append(with_latency)\n",
    "    condition_1_no_latency.append(no_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_trial_data_with_latency = condition_0_with_latency + condition_1_with_latency\n",
    "combined_trial_data_no_latency = condition_0_no_latency + condition_1_no_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_0_with_latency_mouse = []\n",
    "condition_0_no_latency_mouse = []\n",
    "\n",
    "for mouse_df in condition_0_data_mouse:  \n",
    "    with_latency = mouse_df.loc[mouse_df[\"blocknumber\"].isin([1, 2])].copy()\n",
    "    no_latency = mouse_df.loc[mouse_df[\"blocknumber\"].isin([3, 4])].copy()\n",
    "    \n",
    "    condition_0_with_latency_mouse.append(with_latency)\n",
    "    condition_0_no_latency_mouse.append(no_latency)\n",
    "\n",
    "\n",
    "condition_1_with_latency_mouse = []\n",
    "condition_1_no_latency_mouse = []\n",
    "\n",
    "for mouse_df in condition_1_data_mouse:  \n",
    "    with_latency = mouse_df.loc[mouse_df[\"blocknumber\"].isin([3, 4])].copy()\n",
    "    no_latency = mouse_df.loc[mouse_df[\"blocknumber\"].isin([1, 2])].copy()\n",
    "    \n",
    "    condition_1_with_latency_mouse.append(with_latency)\n",
    "    condition_1_no_latency_mouse.append(no_latency)\n",
    "\n",
    "combined_with_latency_mouse = condition_0_with_latency_mouse + condition_1_with_latency_mouse\n",
    "combined_no_latency_mouse = condition_0_no_latency_mouse + condition_1_no_latency_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trialnumber', 'blocknumber', 'success', 'reactiontime',\n",
      "       'currentcongruency', 'currentdirection', 'currentlocation',\n",
      "       'previouscongruency', 'previousdirection', 'previouslocation',\n",
      "       'participant_num', 'timedifference', 'xpos', 'ypos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "combined_with_latency_df = pd.concat(combined_trial_data_with_latency, ignore_index=True)\n",
    "combined_with_latency_mouse_df = pd.concat(combined_with_latency_mouse, ignore_index=True)\n",
    "\n",
    "combined_with_latency_final = pd.merge(\n",
    "    combined_with_latency_df,       \n",
    "    combined_with_latency_mouse_df,\n",
    "    on=[\"trialnumber\", \"blocknumber\", \"participant_num\"],\n",
    "    how=\"inner\"                      \n",
    ")\n",
    "\n",
    "print(combined_with_latency_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10245\n"
     ]
    }
   ],
   "source": [
    "combined_no_latency_df = pd.concat(combined_trial_data_no_latency, ignore_index=True)\n",
    "combined_no_latency_mouse_df = pd.concat(combined_no_latency_mouse, ignore_index=True)\n",
    "\n",
    "combined_no_latency_final = pd.merge(\n",
    "    combined_no_latency_df,       \n",
    "    combined_no_latency_mouse_df,\n",
    "    on=[\"trialnumber\", \"blocknumber\", \"participant_num\"],\n",
    "    how=\"inner\"                      \n",
    ")\n",
    "\n",
    "print(len(combined_no_latency_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fehlerhafte Trials ausschließen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit Latenz: Es wurden 809 fehlerhafte Trials von insgesamt 10204 entfernt\n"
     ]
    }
   ],
   "source": [
    "combined_with_latency_final[\"remove\"] = combined_with_latency_final[\"success\"] == 0\n",
    "combined_with_latency_final[\"remove\"] = combined_with_latency_final[\"remove\"] | combined_with_latency_final[\"remove\"].shift(1, fill_value=0)\n",
    "combined_with_latency_final_errors = combined_with_latency_final[~combined_with_latency_final[\"remove\"]].drop(columns=[\"remove\"])\n",
    "\n",
    "print(f\"Mit Latenz: Es wurden {len(combined_with_latency_final) -  len(combined_with_latency_final_errors)} fehlerhafte Trials von insgesamt {len(combined_with_latency_final)} entfernt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohne Latenz: Es wurden 576 fehlerhafte Trials von insgesamt 10245 entfernt\n"
     ]
    }
   ],
   "source": [
    "combined_no_latency_final[\"remove\"] = combined_no_latency_final[\"success\"] == 0\n",
    "combined_no_latency_final[\"remove\"] = combined_no_latency_final[\"remove\"] | combined_no_latency_final[\"remove\"].shift(1, fill_value=0)\n",
    "combined_no_latency_final_errors = combined_no_latency_final[~combined_no_latency_final[\"remove\"]].drop(columns=[\"remove\"])\n",
    "\n",
    "\n",
    "print(f\"Ohne Latenz: Es wurden {len(combined_no_latency_final) -  len(combined_no_latency_final_errors)} fehlerhafte Trials von insgesamt {len(combined_no_latency_final)} entfernt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausschluss extremer Reaktionszeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittszeit in Trials mit Latenz: 498.9469930814263\n",
      "Durchschnittszeit in Trials ohne Latenz: 441.65715172199816\n"
     ]
    }
   ],
   "source": [
    "averageReactiontimeWithLatency = combined_with_latency_final_errors[\"reactiontime\"].mean()\n",
    "averageReactiontimeNoLatency = combined_no_latency_final_errors[\"reactiontime\"].mean()\n",
    "\n",
    "print(f\"Durchschnittszeit in Trials mit Latenz: {averageReactiontimeWithLatency}\")\n",
    "print(f\"Durchschnittszeit in Trials ohne Latenz: {averageReactiontimeNoLatency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit Latenz: Von 9395 wurden 76 Trials aufgrund von zu hoher Standardabweichung entfernt.\n"
     ]
    }
   ],
   "source": [
    "mean_rt_with_latency = combined_with_latency_final_errors[\"reactiontime\"].mean()\n",
    "std_rt_with_latency = combined_with_latency_final_errors[\"reactiontime\"].std()\n",
    "\n",
    "combined_with_latency_final_errors[\"outlier\"] = (combined_with_latency_final_errors[\"reactiontime\"] < mean_rt_with_latency - 4 * std_rt_with_latency) | (combined_with_latency_final_errors[\"reactiontime\"] > mean_rt_with_latency + 4 * std_rt_with_latency)\n",
    "\n",
    "combined_with_latency_final_outliers = combined_with_latency_final_errors[~combined_with_latency_final_errors[\"outlier\"]].drop(columns=[\"outlier\"])\n",
    "\n",
    "print(f\"Mit Latenz: Von {len(combined_with_latency_final_errors)} wurden {len(combined_with_latency_final_errors) - len(combined_with_latency_final_outliers)} Trials aufgrund von zu hoher Standardabweichung entfernt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohne Latenz: Von 9669 wurden 59 Trials aufgrund von zu hoher Standardabweichung entfernt.\n"
     ]
    }
   ],
   "source": [
    "mean_rt_no_latency = combined_no_latency_final_errors[\"reactiontime\"].mean()\n",
    "std_rt_no_latency = combined_no_latency_final_errors[\"reactiontime\"].std()\n",
    "\n",
    "combined_no_latency_final_errors[\"outlier\"] = (combined_no_latency_final_errors[\"reactiontime\"] < mean_rt_no_latency - 4 * std_rt_no_latency) | (combined_no_latency_final_errors[\"reactiontime\"] > mean_rt_no_latency + 4 * std_rt_no_latency)\n",
    "\n",
    "combined_no_latency_final_outliers = combined_no_latency_final_errors[~combined_no_latency_final_errors[\"outlier\"]].drop(columns=[\"outlier\"])\n",
    "\n",
    "print(f\"Ohne Latenz: Von {len(combined_no_latency_final_errors)} wurden {len(combined_no_latency_final_errors) - len(combined_no_latency_final_outliers)} Trials aufgrund von zu hoher Standardabweichung entfernt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_no_latency_final_outliers[\"latency\"] = 1\n",
    "combined_with_latency_final_outliers[\"latency\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_no_latency_final_outliers.to_pickle(\"preprocessed_data/preprocessed_no_latency.pkl\")\n",
    "combined_with_latency_final_outliers.to_pickle(\"preprocessed_data/preprocessed_with_latency.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
